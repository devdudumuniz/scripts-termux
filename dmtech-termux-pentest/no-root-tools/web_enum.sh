#!/data/data/com.termux/files/usr/bin/bash
# -*- coding: utf-8 -*-
#
# Web Enumeration - Enumeração de diretórios web sem ROOT
# Descoberta de diretórios e arquivos em servidores web
#
# PRÉ-REQUISITOS:
#   - curl
#
# USO:
#   ./web_enum.sh <url_base> [wordlist]
#

set -e

# Cores
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'
NC='\033[0m'

# Configurações
URL_BASE="${1}"
WORDLIST="${2}"
OUTPUT_DIR="../output"
LOG_DIR="../logs"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
THREADS=10

# Criar diretórios
mkdir -p "$OUTPUT_DIR/json" "$OUTPUT_DIR/csv" "$LOG_DIR"

# Arquivo de log
LOGFILE="$LOG_DIR/web_enum_${TIMESTAMP}.log"

# Função de log
log() {
    echo -e "${CYAN}[$(date +'%H:%M:%S')]${NC} $1" | tee -a "$LOGFILE"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1" | tee -a "$LOGFILE"
}

log_success() {
    echo -e "${GREEN}[✓]${NC} $1" | tee -a "$LOGFILE"
}

# Verificar URL
check_url() {
    if [ -z "$URL_BASE" ]; then
        log_error "URL não fornecida"
        echo "Uso: $0 <url_base> [wordlist]"
        exit 1
    fi
    
    # Remover trailing slash
    URL_BASE="${URL_BASE%/}"
    
    log "URL alvo: $URL_BASE"
}

# Criar wordlist básica se não fornecida
create_wordlist() {
    if [ -z "$WORDLIST" ] || [ ! -f "$WORDLIST" ]; then
        log "Criando wordlist básica..."
        
        WORDLIST="/tmp/web_enum_wordlist_${TIMESTAMP}.txt"
        
        cat > "$WORDLIST" << 'EOF'
admin
administrator
login
dashboard
panel
cpanel
phpmyadmin
wp-admin
wp-login
backup
backups
config
configuration
database
db
sql
api
test
dev
development
staging
uploads
upload
files
images
img
css
js
assets
static
private
secret
hidden
temp
tmp
logs
log
error
errors
debug
old
new
bak
backup
archive
archives
data
docs
documents
download
downloads
include
includes
lib
libs
library
src
source
vendor
node_modules
.git
.env
.htaccess
robots.txt
sitemap.xml
README.md
CHANGELOG.md
package.json
composer.json
web.config
EOF
        
        log_success "Wordlist criada: $WORDLIST"
    else
        log "Usando wordlist: $WORDLIST"
    fi
}

# Enumerar diretórios
enumerate_dirs() {
    log "Iniciando enumeração web..."
    
    python3 << 'PYEOF'
import urllib.request
import urllib.error
import json
import csv
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import ssl

URL_BASE = "$URL_BASE"
WORDLIST = "$WORDLIST"
OUTPUT_DIR = "$OUTPUT_DIR"
TIMESTAMP = "$TIMESTAMP"
THREADS = $THREADS
TIMEOUT = 5

# Ignorar verificação SSL (para testes)
ssl_context = ssl._create_unverified_context()

def check_path(path):
    """Verifica se um caminho existe"""
    url = f"{URL_BASE}/{path}"
    
    try:
        req = urllib.request.Request(
            url,
            headers={'User-Agent': 'Mozilla/5.0 (Linux; Android 10) AppleWebKit/537.36'}
        )
        
        with urllib.request.urlopen(req, timeout=TIMEOUT, context=ssl_context) as response:
            status_code = response.getcode()
            content_length = response.headers.get('Content-Length', 'Unknown')
            content_type = response.headers.get('Content-Type', 'Unknown')
            
            return {
                'path': path,
                'url': url,
                'status': status_code,
                'size': content_length,
                'type': content_type,
                'timestamp': datetime.now().isoformat()
            }
    
    except urllib.error.HTTPError as e:
        if e.code in [401, 403]:  # Unauthorized/Forbidden = existe mas protegido
            return {
                'path': path,
                'url': url,
                'status': e.code,
                'size': 'Protected',
                'type': 'Unknown',
                'timestamp': datetime.now().isoformat()
            }
    except:
        pass
    
    return None

# Ler wordlist
with open(WORDLIST, 'r') as f:
    paths = [line.strip() for line in f if line.strip() and not line.startswith('#')]

print(f"Testando {len(paths)} caminhos em {URL_BASE}...")

found_paths = []
completed = 0

with ThreadPoolExecutor(max_workers=THREADS) as executor:
    futures = {executor.submit(check_path, path): path for path in paths}
    
    for future in as_completed(futures):
        completed += 1
        result = future.result()
        
        if result:
            found_paths.append(result)
            status = result['status']
            
            if status == 200:
                print(f"[+] {result['url']} - {status} - {result['size']} bytes")
            elif status in [401, 403]:
                print(f"[!] {result['url']} - {status} (Protected)")
        
        if completed % 50 == 0:
            print(f"[*] Progresso: {completed}/{len(paths)}")

# Salvar JSON
json_output = f"{OUTPUT_DIR}/json/web_enum_{TIMESTAMP}.json"
with open(json_output, 'w', encoding='utf-8') as f:
    json.dump({
        'scan_timestamp': datetime.now().isoformat(),
        'target': URL_BASE,
        'total_tested': len(paths),
        'total_found': len(found_paths),
        'paths': found_paths
    }, f, indent=2, ensure_ascii=False)

# Salvar CSV
csv_output = f"{OUTPUT_DIR}/csv/web_enum_{TIMESTAMP}.csv"
if found_paths:
    with open(csv_output, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=found_paths[0].keys())
        writer.writeheader()
        writer.writerows(found_paths)

print(f"\nEncontrados {len(found_paths)} caminhos de {len(paths)} testados")
print(f"JSON: {json_output}")
print(f"CSV: {csv_output}")
PYEOF
    
    log_success "Enumeração concluída"
}

# Cleanup
cleanup() {
    if [ -f "/tmp/web_enum_wordlist_${TIMESTAMP}.txt" ]; then
        rm -f "/tmp/web_enum_wordlist_${TIMESTAMP}.txt"
    fi
}

trap cleanup EXIT

# Main
main() {
    echo -e "${CYAN}═══════════════════════════════════════════════════════════${NC}"
    echo -e "${YELLOW}  Web Enumeration - DMTech Pentest${NC}"
    echo -e "${CYAN}═══════════════════════════════════════════════════════════${NC}"
    echo ""
    
    check_url
    create_wordlist
    enumerate_dirs
    
    echo ""
    log_success "Enumeração web concluída com sucesso!"
}

main
